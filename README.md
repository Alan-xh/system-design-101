<p>
  <a href="https://blog.bytebytego.com/?utm_source=site"><img src="images/banner.jpg" /> </a>
</p>

<p align="center">
  【
  <a href="https://www.youtube.com/channel/UCZgt6AzoyjslHTC9dz0UoTw">
    👨None🏻‍None💻 YouTube
  </a> | 
  <a href="https://blog.bytebytego.com/?utm_source=site">
    📮 通讯
  </a> 】
</p>

<a href="https://trendshift.io/repositories/3709" target="_blank"><img src="https://trendshift.io/api/badge/repositories/3709" alt="ByteByteGoHq%2Fsystem-design-101 | Trendshift" style="width: 250px; height: 55px;" width="250" height="55"/></a>

# 系统设计101

使用可视化和简单术语来解释复杂系统。

无论您是在准备系统设计面试还是只是想了解系统在表面下的工作原理，我们希望这个仓库能帮助您实现这一目标。

# 目录

<!-- TOC toc.levels=2 -->

- [通信协议](#通信协议)
  - [REST API 与 GraphQL](#rest-api-与-graphql)
  - [gRPC 如何工作？](#grpc-如何工作)
  - [什么是 webhook？](#什么是-webhook)
  - [如何提升API性能？](#如何提升api性能)
  - [HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)](#http-10---http-11---http-20---http-30-quic)
  - [SOAP vs REST vs GraphQL vs RPC](#soap-vs-rest-vs-graphql-vs-rpc)
  - [代码优先与API优先](#代码优先与api优先)
  - [HTTP状态码](#http状态码)
  - [API网关的功能是什么？](#api网关的功能是什么)
  - [如何设计有效且安全的API？](#如何设计有效且安全的api)
  - [TCP/IP封装](#tcpip封装)
  - [为什么Nginx被称为“反向”代理？](#为什么nginx被称为反向代理)
  - [常见的负载均衡算法有哪些？](#常见的负载均衡算法有哪些)
  - [URL, URI, URN - 你知道它们的区别吗？](#url-uri-urn---你知道它们的区别吗)
- [CI/CD](#cicd)
  - [用简单术语解释CI/CD管道](#用简单术语解释cicd管道)
  - [Netflix技术堆栈（CI/CD管道）](#netflix技术堆栈cicd管道)
- [架构模式](#架构模式)
  - [MVC, MVP, MVVM, MVVM-C和VIPER](#mvc-mvp-mvvm-mvvm-c和viper)
  - [每个开发者都应该知道的18个关键设计模式](#每个开发者都应该知道的18个关键设计模式)
- [数据库](#数据库)
  - [云服务中不同数据库的简要概述](#云服务中不同数据库的简要概述)
  - [8种支持数据库的数据结构](#8种支持数据库的数据结构)
  - [SQL语句如何在数据库中执行？](#sql语句如何在数据库中执行)
  - [CAP定理](#cap定理)
  - [内存和存储的类型](#内存和存储的类型)
  - [可视化SQL查询](#可视化sql查询)
  - [SQL语言](#sql语言)
- [缓存](#缓存)
  - [数据无处不在](#数据无处不在)
  - [为什么Redis这么快？](#为什么redis这么快)
  - [Redis有哪些用途？](#redis有哪些用途)
  - [顶级缓存策略](#顶级缓存策略)
- [微服务架构](#微服务架构)
  - [典型的微服务架构是什么样的？](#典型的微服务架构是什么样的)
  - [微服务最佳实践](#微服务最佳实践)
  - [微服务常用的技术堆栈是什么？](#微服务常用的技术堆栈是什么)
  - [为什么Kafka这么快](#为什么kafka这么快)
- [支付系统](#支付系统)
  - [如何学习支付系统？](#如何学习支付系统)
  - [为什么信用卡被称为“银行最赚钱的产品”？Visa/Mastercard是如何盈利的？](#为什么信用卡被称为银行最赚钱的产品-visamastercard是如何盈利的)
  - [当我们在商店刷信用卡时，Visa是如何工作的？](#当我们在商店刷信用卡时-visa是如何工作的)
  - [全球支付系统系列（第一部分）：印度的统一支付接口（UPI）](#全球支付系统系列第一部分印度的统一支付接口upi)
- [DevOps](#devops)
  - [DevOps vs. SRE vs. 平台工程。有什么区别？](#devops-vs-sre-vs-平台工程有什么区别)
  - [什么是k8s（Kubernetes）？](#什么是k8s-kubernetes)
  - [Docker vs. Kubernetes。应该使用哪个？](#docker-vs-kubernetes-应该使用哪个)
  - [Docker是如何工作的？](#docker是如何工作的)
- [GIT](#git)
  - [Git命令如何工作](#git命令如何工作)
  - [Git如何工作？](#git如何工作)
  - [Git合并与Git变基](#git合并与git变基)
- [云服务](#云服务)
  - [不同云服务的简要概述（2023版）](#不同云服务的简要概述2023版)
  - [什么是云原生？](#什么是云原生)
- [开发者生产力工具](#开发者生产力工具)
  - [可视化JSON文件](#可视化json文件)
  - [自动将代码转换为架构图](#自动将代码转换为架构图)
- [Linux](#linux)
  - [Linux文件系统解释](#linux文件系统解释)
  - [你应该知道的18个最常用的Linux命令](#你应该知道的18个最常用的linux命令)
- [安全](#安全)
  - [HTTPS是如何工作的？](#https是如何工作的)
  - [用简单术语解释OAuth 2.0](#用简单术语解释oauth-20)
  - [四种主要的认证机制](#四种主要的认证机制)
  - [会话、Cookie、JWT、令牌、SSO和OAuth 2.0 - 它们是什么？](#会话cookie-jwt-令牌sso和oauth-20---它们是什么)
  - [如何在数据库中安全存储密码以及如何验证密码？](#如何在数据库中安全存储密码以及如何验证密码)
  - [向10岁小孩解释JSON Web Token (JWT)](#向10岁小孩解释json-web-token-jwt)
  - [Google Authenticator（或其他类型的双因素认证器）是如何工作的？](#google-authenticator或其他类型的双因素认证器是如何工作的)
- [现实世界的案例研究](#现实世界的案例研究)
  - [Netflix的技术堆栈](#netflix的技术堆栈)
  - [Twitter架构2022](#twitter架构2022)
  - [过去15年Airbnb微服务架构的演变](#过去15年airbnb微服务架构的演变)
  - [单体仓库 vs. 微仓库](#单体仓库-vs-微仓库)
  - [你将如何设计Stack Overflow网站？](#你将如何设计stack-overflow网站)
  - [为什么Amazon Prime Video监控从无服务器转向单体架构？它如何节省90%的成本？](#为什么amazon-prime-video监控从无服务器转向单体架构它如何节省90的成本)
  - [Disney Hotstar在比赛期间如何捕获50亿个表情符号？](#disney-hotstar在比赛期间如何捕获50亿个表情符号)
  - [Discord如何存储万亿条消息](#discord如何存储万亿条消息)
  - [YouTube、TikTok直播或Twitch上的视频直播是如何工作的？](#youtube-tiktok直播或twitch上的视频直播是如何工作的)

<!-- /TOC -->


question = r"""
翻译以下文本,切记保持md格式
## Communication protocols

Architecture styles define how different components of an application programming interface (API) interact with one another. As a result, they ensure efficiency, reliability, and ease of integration with other systems by providing a standard approach to designing and building APIs. Here are the most used styles:

<p>
  <img src="images/api-architecture-styles.png" style="width: 640px">
</p>

## 通信协议

架构风格定义了应用程序接口（API）不同组件之间的交互方式。因此，它们通过提供设计和构建API的标准方法，确保了效率、可靠性以及与其他系统的易集成。以下是最常用的风格：

<p>
  <img src="images/api-architecture-styles.png" style="width: 640px">
</p>

- **SOAP**：

  成熟、全面、基于XML
  
  最适合企业应用

- **RESTful**：

  流行、易于实现、使用HTTP方法
  
  非常适合Web服务

- **GraphQL**：

  查询语言，请求特定数据
  
  减少网络开销，响应更快

- **gRPC**：

  现代、高性能，使用Protocol Buffers
  
  适用于微服务架构

- **WebSocket**：

  实时、双向、持久连接
  
  非常适合低延迟数据交换

- **Webhook**：

  事件驱动、HTTP回调、异步
  
  在事件发生时通知系统


### REST API与GraphQL对比

在API设计中，REST和GraphQL各有其优势和劣势。

下图显示了REST和GraphQL之间的快速对比。

<p>
  <img src="images/graphQL.jpg">
</p>

**REST**

- 使用标准的HTTP方法如GET、POST、PUT、DELETE来进行CRUD操作。
- 当需要在独立的服务/应用程序之间提供简单统一的接口时效果很好。
- 缓存策略易于实现。
- 缺点是可能需要多次往返来从不同的端点组装相关数据。

**GraphQL**

- 提供一个单一端点让客户端可以查询他们需要的确切数据。
- 客户端可以指定嵌套查询中需要的精确字段，服务器返回仅包含这些字段的优化负载。
- 支持Mutation来修改数据和Subscription来进行实时通知。
- 适用于从多个来源聚合数据，适用于前端需求快速变化的情况。
- 然而，它将复杂性转移到了客户端，如果不加以保护，可能会允许None滥用查询。
- 缓存策略可能比REST更复杂。

REST和GraphQL之间的最佳选择取决于应用和开发团队的具体需求。GraphQL适合复杂或经常变化的前端需求，而REST则适用于偏好简单和一致性合同的应用。

没有哪种API方法是万能的。仔细评估需求和权衡是选择正确风格的关键。REST和GraphQL都是有效的选择，用于公开数据和支持现代应用程序。


### gRPC如何工作？

RPC（远程过程调用）被称为“**远程**”，因为它在微服务架构下允许不同服务器上的服务之间的通信。从用户的角度来看，它就像一个本地函数调用。

下图展示了**gRPC**的整体数据流。

<p>
  <img src="images/grpc.jpg">
</p>

步骤1：客户端发起一个REST调用。请求体通常为JSON格式。

步骤2 - 4：订单服务（gRPC客户端）接收REST调用，进行转换，并向支付服务发起RPC调用。gRPC将**客户端存根**编码为二进制格式并发送到低层传输层。

步骤5：gRPC通过HTTP2在网络上传送数据包。由于二进制编码和网络优化，gRPC被认为比JSON快5倍。

步骤6 - 8：支付服务（gRPC服务器）从网络接收数据包，解码它们，并调用服务器应用程序。

步骤9 - 11：结果从服务器应用程序返回，编码并发送到传输层。

步骤12 - 14：订单服务接收数据包，解码它们，并将结果发送到客户端应用程序。

### Webhook是什么？

下图展示了轮询和Webhook的比较。

<p>
  <img src="images/webhook.jpeg" style="width: 680px" />
</p>

假设我们运营一个电子商务网站。客户通过API网关将订单发送到订单服务，订单服务再转到支付服务处理支付交易。支付服务然后与外部支付服务提供商（PSP）通信以完成交易。

与外部PSP的通信有两种方式：

**1. 短轮询**

在向PSP发送支付请求后，支付服务不断询问PSP支付状态。在几轮询问后，PSP最终返回状态。

短轮询有两个缺点：
* 持续的轮询状态需要支付服务的资源。
* 外部服务直接与支付服务通信，存在安全漏洞。

**2. Webhook**

我们可以向外部服务注册一个webhook。这意味着：当你有请求更新时，请回调到某个特定的URL。当PSP完成处理时，它将通过HTTP请求来更新支付状态。

这样，编程范式发生了变化，支付服务不再需要浪费资源去轮询支付状态。

如果PSP从未回调呢？我们可以设置一个每小时检查一次支付状态的家务清理作业。

Webhook通常被称为反向API或推送API，因为服务器会向客户端发送HTTP请求。在使用webhook时，我们需要注意3件事：

1. 我们需要为外部服务设计一个合适的API。
2. 为了安全原因，我们需要在API网关设置适当的规则。
3. 我们需要在外部服务注册正确的URL。

### 如何提高API性能？

下图展示了5个常见的提高API性能的技巧。

<p>
  <img src="images/api-performance.jpg">
</p>

分页

当结果集非常大时，这是常见的优化方法。结果会流式传输回客户端以提高服务的响应性。

异步日志

同步日志每次调用都会与磁盘交互，可能减慢系统。异步日志首先将日志发送到无锁缓冲区并立即返回。日志将定期刷新到磁盘。这显著减少了I/O开销。

缓存

我们可以将经常访问的数据存储到缓存中。客户端可以先查询缓存而不是直接访问数据库。如果缓存未命中，客户端可以从数据库查询。像Redis这样的缓存将数据存储在内存中，因此数据访问速度比数据库快得多。

负载压缩

请求和响应可以使用gzip等压缩，这样传输的数据大小会小很多。这加速了上传和下载。

连接池

在访问资源时，我们经常需要从数据库加载数据。打开和关闭数据库连接会带来很大的开销。因此，我们应该通过一个开放连接池连接到数据库。连接池负责管理连接的生命周期。

### HTTP 1.0 -> HTTP 1.1 -> HTTP 2.0 -> HTTP 3.0 (QUIC)

每一代HTTP解决了什么问题？

下图说明了关键特性。

<p>
  <img src="images/http3.jpg" />
</p>

- HTTP 1.0于1996年最终确定并完全文档化。对同一服务器的每次请求都需要一个单独的TCP连接。

- HTTP 1.1于1997年发布。TCP连接可以保持打开以供重用（持久连接），但它没有解决HOL（队首阻塞）问题。

  HOL阻塞 - 当浏览器中允许的并行请求数用尽时，后续请求需要等待前面的请求完成。

- HTTP 2.0于2015年发布。它通过请求多路复用解决了HOL问题，这消除了应用层面的HOL阻塞，但传输层（TCP）层仍然存在HOL。

  如图所示，HTTP 2.0引入了HTTP“流”的概念：这是一个允许将不同的HTTP交换复用到同一TCP连接上的抽象。每个流不需要按顺序发送。

- HTTP 3.0的初稿于2020年发布。它是HTTP 2.0的建议继任者。它使用QUIC而不是TCP作为底层传输协议，从而在传输层上消除了HOL阻塞。

QUIC基于UDP。它在传输层引入流作为一等公民。QUIC流共享同一个QUIC连接，因此不需要额外的手握和慢启动来创建新的流，但QUIC流独立传送，这样在大多数情况下，影响一个流的数据包丢失不会影响其他流。

### SOAP vs REST vs GraphQL vs RPC

下图展示了API时间线和API风格比较。

随着时间的推移，发布了不同的API架构风格。它们每一种都有标准化数据交换的模式。

您可以在图表中查看每种风格的使用案例。

<p>
  <img src="images/SOAP vs REST vs GraphQL vs RPC.jpeg" />
</p>

### 代码优先 vs. API优先

下图展示了代码优先开发和API优先开发之间的差异。为什么我们要考虑API优先设计？

<p>
  <img src="images/api_first.jpg" style="width: 680px" />
</p>

- 微服务增加了系统的复杂性，我们有独立的服务来服务系统的不同功能。虽然这种架构便于解None耦和职责分离，但我们需要处理服务间的各种通信。

在编写代码之前，最好先考虑系统的复杂性，并仔细定义服务的边界。

- 独立的功能团队需要使用相同的语言，并且专职的功能团队只负责他们自己的组件和服务。建议通过API设计使组织内部使用相同的语言。

我们可以在编写代码之前通过模拟请求和响应来验证API设计。

- 提高软件质量和开发者生产力 由于在项目开始时我们已经解决了大部分不确定性，整个开发过程更加顺畅，软件质量也大大提高。

开发者也对这一过程感到满意，因为他们可以专注于功能开发，而不是应对突然的变更。

在项目生命周期末期出现意外情况的可能性降低了。

因为我们首先设计了API，所以可以在代码开发的同时设计测试。在某种程度上，使用API优先开发也是一种TDD（测试驱动设计）。

### HTTP状态码

<p>
  <img src="images/http-status-code.jpg" style="width: 540px" />
</p>

HTTP的响应代码分为五类：

信息性（100-199）
成功（200-299）
重定向（300-399）
客户端错误（400-499）
服务器错误（500-599）

### API网关做什么？

下图显示了详细信息。

<p>
  <img src="images/api_gateway.jpg" style="width: 520px" />
</p>

步骤1 - 客户端向API网关发送HTTP请求。

步骤2 - API网关解析并验证HTTP请求中的属性。

步骤3 - API网关执行允许列表/拒绝列表检查。

步骤4 - API网关与身份提供者进行身份验证和授权。

步骤5 - 对请求应用速率限制规则。如果超出限制，请求将被拒绝。

步骤6和7 - 现在请求已经通过了基本检查，API网关通过路径匹配找到相关的服务进行路由。

步骤8 - API网关将请求转换为适当的协议并发送到后端微服务。

步骤9-12：API网关可以正确处理错误，并在错误恢复时间较长的情况下处理故障（断路）。它还可以利用ELK（Elastic-Logstash-Kibana）堆栈进行日志记录和监控。有时我们在API网关中缓存数据。

### 如何设计有效且安全的API？

下图展示了一个典型的API设计示例，以购物车为例。

<p>
  <img src="images/safe-apis.jpg" />
</p>

注意，API设计不仅仅是URL路径设计。大多数时候，我们需要选择适当的资源名称、标识符和路径模式。设计适当的HTTP头字段或在API网关内设计有效的速率限制规则同样重要。

### TCP/IP封装

数据如何通过网络发送？为什么我们在OSI模型中需要这么多层？

下图显示了数据在网络传输时如何被封装和解封装的过程。

<p>
  <img src="images/osi model.jpeg" />
</p>

步骤1：当设备A通过HTTP协议向设备B发送数据时，首先在应用层添加HTTP头。

步骤2：然后在数据上添加TCP或UDP头。在传输层封装成TCP段。头部包含源端口、目标端口和序列号。

步骤3：这些段然后在网络层被添加IP头。IP头包含源/目标IP地址。

步骤4：IP数据报在数据链路层被添加MAC头，包含源/目标MAC地址。

步骤5：封装好的None帧被发送到物理层，并以二进制位的形式通过网络发送。

步骤6-10：当设备B从网络接收到比特时，它执行解封装过程，这是封装过程的逆操作。逐层移除头部，最终设备B可以读取数据。

我们需要网络模型中的层，因为每一层都专注于自己的职责。每层可以依赖头部来获取处理指令，而不需要知道上一层数据的含义。


下图展示了**前向代理**和**反向代理**之间的区别。

<p>
  <img src="images/Forward Proxy v.s. Reverse Proxy2x.jpg" style="width: 720px" />
</p>

前向代理是位于用户设备和互联网之间的服务器。

前向代理常用于：

1. 保护客户端
2. 绕过浏览限制
3. 阻止访问某些内容

反向代理是接受来自客户端的请求，将请求转发给Web服务器，然后将结果返回给客户端，仿佛代理服务器自己处理了该请求。

反向代理适合：

1. 保护服务器
2. 负载均衡
3. 缓存静态内容
4. 加密和解密SSL通信

### 常见的负载均衡算法有哪些？

下图展示了六种常见的算法。

<p>
  <img src="images/lb-algorithms.jpg" />
</p>

- **静态算法**

1. **轮询（Round robin）**

    客户端请求按顺序发送到不同的服务实例。服务通常需要是无状态的。

3. **粘性轮询（Sticky round-robin）**

    这是轮询算法的改进。如果Alice的第一次请求发送到服务A，后续请求也会发送到服务A。

4. **加权轮询（Weighted round-robin）**

    管理员可以为每个服务指定权重。权重较高的服务会处理更多的请求。

6. **哈希（Hash）**

    这个算法对传入请求的IP或URL应用哈希函数。根据哈希函数的结果，请求被路由到相关实例。

- **动态算法**

5. **最少连接（Least connections）**

    新的请求被发送到当前连接数最少的服务实例。

7. **最短响应时间（Least response time）**

    新的请求被发送到响应时间最快的服务实例。

### URL、URI、URN - 你知道它们的区别吗？

下图展示了URL、URI和URN的比较。

<p>
  <img src="images/url-uri-urn.jpg" />
</p>

- **URI**

    URI代表统一资源标识符。它标识Web上的逻辑或物理资源。URL和URN是URI的子类型。URL定位资源，而URN命名资源。

    URI由以下部分组成：
    ```text
    scheme:[//authority]path[?query][#fragment]
    ```

- **URL**

    URL代表统一资源定位器，是HTTP的关键概念。它是Web上唯一资源的地址。可以与其他协议如FTP和JDBC一起使用。

- **URN**

    URN代表统一资源名称。它使用urn方案。URN不能用于定位资源。图中给出的简单示例由命名空间和命名空间特定的字符串组成。

如果您想更深入了解这个主题，我推荐查阅[W3C的澄清](https://www.w3.org/TR/uri-clarification/)。


## CI/CD

### 以简单术语解释CI/CD Pipeline

<p>
  <img src="images/ci-cd-pipeline.jpg" style="width: 680px" />
</p>

**第1节 - 包含CI/CD的软件开发生命周期（SDLC）**

软件开发生命周期（SDLC）包括几个关键阶段：开发、测试、部署和维护。CI/CD自动化并整合这些阶段，以实现更快、更可靠的发布。

当代码推送到git仓库时，它会触发自动构建和测试过程。端到端（e2e）测试用例被运行以验证代码。如果测试通过，代码可以自动部署到暂存/生产环境。如果发现问题，代码会被退回给开发团队进行错误修复。这种自动化提供给开发人员快速反None馈，并降低了生产环境中的错误风险。

**第2节 - CI与CD的区别**

持续集成（CI）自动化构建、测试和合并过程。每当代码提交时运行测试，以尽早发现集成问题。这鼓励频繁提交代码并提供快速反None馈。

持续交付（CD）自动化发布过程，如基础设施变更和部署。它确保软件可以随时通过自动化工作流程可靠地发布。CD也可能自动化在生产部署之前所需的手动测试和批准步骤。

**第3节 - CI/CD Pipeline**

一个典型的CI/CD管道有几个连接的阶段：
- 开发者将代码更改提交到源代码控制
- CI服务器检测到变化并触发构建
- 代码被编译并进行测试（单元测试、集成测试）
- 测试结果报告给开发者
- 成功后，工件被部署到暂存环境
- 在发布之前可能在暂存环境中进行进一步测试
- CD系统将批准的更改部署到生产环境

### Netflix技术栈（CI/CD Pipeline）

<p>
  <img src="images/netflix-ci-cd.jpg" style="width: 720px" />
</p>

规划：Netflix工程使用JIRA进行规划和Confluence进行文档记录。

编码：Java是后端服务的主要编程语言，而其他语言用于不同的用例。

构建：主要使用Gradle进行构建，并构建了Gradle插件以支持各种用例。

打包：将包和依赖项打包到Amazon Machine Image（AMI）中以进行发布。

测试：测试强调生产文化的重点，即构建混乱工具。

部署：Netflix使用自建的Spinnaker进行金丝雀发布部署。

监控：监控指标集中在Atlas中，使用Kayenta检测异常。

事件报告：根据优先级分派事件，并使用PagerDuty处理事件。

## 架构模式

### MVC, MVP, MVVM, MVVM-C和VIPER
这些架构模式在iOS或Android平台的应用程序开发中是最常用的，开发者们引入了它们以克服早期模式的局限性。那么，它们有何不同？

<p>
  <img src="images/client arch patterns.png" style="width: 720px" />
</p>

- MVC是最古老的模式，历史可以追None溯到近50年
- 每个模式都有一个“视图”（V），负责显示内容和接收用户输入
- 大多数模式包括一个“模型”（M）来管理业务数据
- “控制器”、“演示者”和“视图模型”作为翻译器，在视图和模型之间进行中介（在VIPER模式中是“实体”）

### 每个开发者都应该知道的18个关键设计模式

模式是常见设计问题的可重用解决方案，导致开发过程更加顺畅、更有效率。它们作为构建更好软件结构的蓝图。以下是一些最流行的模式：

<p>
  <img src="images/18-oo-patterns.png" />
</p>

- 抽象工厂：家庭创造者 - 制作相关项目的组。
- 建造者：乐高大师 - 分步骤构建对象，保持创建与外观分离。
- 原型：克隆制造者 - 创建完全准备好的实例的副本。
- 单例：独一无二 - 只有一个实例的特殊类。
- 适配器：通用插头 - 连接具有不同接口的事物。
- 桥接：功能连接器 - 链接对象的功能与其执行方式。
- 组合：树形结构建造者 - 形成简单和复杂部分的树状结构。
- 装饰者：定制者 - 在不改变核心的情况下添加对象的功能。
- 外观：一站式服务 - 用一个简化的接口代表整个系统。
- 享元：空间节省者 - 高效共享小型、可重用项目。
- 代理：替身演员 - 代表另一个对象，控制访问或行为。
- 责任链：请求中继 - 通过一系列对象传递请求直到处理。
- 命令：任务包装器 - 将请求变成一个对象，准备执行。
- 迭代器：集合探索者 - 逐个访问集合中的元素。
- 中介者：沟通中心 - 简化不同类之间的交互。
- 备忘录：时间None胶囊 - 捕获和恢复对象的状态。
- 观察者：新闻广播 - 通知类关于其他对象的变化。
- 访问者：熟练的访客 - 向类添加新操作而不改变它。

## 数据库

### 云服务中不同数据库的简明速查表

<p>
  <img src="images/cloud-dbs2.png" />
</p>

为您的项目选择正确的数据库是一项复杂的任务。许多数据库选项，每个适合不同的用例，很快会导致决策疲劳。

我们希望这个速查表能提供高层次的指导，帮助您找到与项目需求相匹配的服务，并避免潜在的陷None阱。

注意：Google对其数据库用例的文档有限。尽管我们尽最大努力查看可用信息并得出最佳选择，但某些条目可能不够准确。

### 8种支持数据库的数据结构

答案将根据您的用例而有所不同。数据可以在内存中或磁盘上编制索引。同样，数据格式也各不相同，如数字、字符串、地理坐标等。系统可能是写入密集型或读取密集型。这些因素都会影响您选择数据库索引格式。

<p>
  <img src="images/8-ds-db.jpg" />
</p>

以下是一些最流行的用于索引数据的数据结构：

- 跳表：常见的内存索引类型。用于Redis
- 哈希索引：非常常见的“Map”数据结构（或“集合”）实现
- SSTable：不可变的磁盘“Map”实现
- LSM树：跳表 + SSTable。高写入吞吐量
- B树：基于磁盘的解决方案。一致的读写性能
- 倒排索引：用于文档索引。用于Lucene
- 后缀树：用于字符串模式搜索
- R树：多维搜索，例如查找最近邻居

### SQL语句在数据库中是如何执行的？

下面的图表展示了这个过程。请注意，不同数据库的架构不同，图表展示了一些常见的设计。

<p>
  <img src="images/sql execution order in db.jpeg" style="width: 580px" />
</p>


步骤1 - 通过传输层协议（如TCP）将SQL语句发送到数据库。

步骤2 - SQL语句被发送到命令解析器，在那里它经过语法和语义分析，随后生成查询树。

步骤3 - 查询树被发送到优化器。优化器创建一个执行计划。

步骤4 - 执行计划被发送到执行器。执行器从执行中检索数据。

步骤5 - 访问方法提供执行所需的数据获取逻辑，从存储引擎中检索数据。

步骤6 - 访问方法决定SQL语句是否为只读。如果查询是只读的（SELECT语句），它会被传递给缓冲区管理器进行进一步处理。缓冲区管理器在缓存或数据文件中查找数据。

步骤7 - 如果语句是UPDATE或INSERT，它会被传递给事务管理器进行进一步处理。

步骤8 - 在事务过程中，数据处于锁定模式。这由锁管理器保证。它还确保了事务的ACID属性。

### CAP定理

CAP定理是计算机科学中最著名的术语之一，但我想不同的开发人员对此有不同的理解。让我们看看它是什么以及为什么它可能令人困惑。

<p>
  <img src="images/cap theorem.jpeg" />
</p>

CAP定理指出，一个分布式系统不能同时提供这三个保证中的两个。

**一致性**：一致性意味着所有客户端在同一时间看到相同的数据，无论他们连接到哪个节点。

**可用性**：可用性意味着任何请求数据的客户端即使在某些节点出现故障的情况下也能得到响应。

**分区容忍性**：分区表示两个节点之间的通信中断。分区容忍性意味着系统在网络分区的情况下继续运行。

“2选3”的表述可能有用，**但这种简化可能具有误导性**。

1. 选择数据库并不容易。仅仅基于CAP定理来选择数据库是不够的。例如，公司选择Cassandra并不是因为它是一个AP系统，而是因为它有一些好的特性，使其成为存储聊天消息的理想选择。我们需要深入探讨。

2. “CAP只禁止了设计空间中的一小部分：在分区存在的情况下完美的可用性和一致性，这是罕见的”。引用自论文：《CAP十二年后：规则如何改变》。

3. 定理是关于100%的可用性和一致性。一个更现实的讨论是在没有网络分区的情况下，延迟和一致性之间的权衡。请参阅PACELC定理了解更多详情。

**CAP定理实际上有用吗？**

我认为它仍然有用，因为它开启了我们对一系列权衡讨论的思考，但它只是故事的一部分。我们在选择合适的数据库时需要更深入的了解。

### 内存和存储的类型

<p>
  <img src="images/Types_of_Memory_and_Storage.jpeg" style="width: 420px" />
</p>


### 可视化SQL查询

<p>
  <img src="images/sql-execution-order.jpg" style="width: 580px" />
</p>

SQL语句由数据库系统通过几个步骤来执行，包括：

- 解析SQL语句并检查其有效性
- 将SQL转换为内部表示，如关系代数
- 优化内部表示并利用索引信息创建执行计划
- 执行计划并返回结果

SQL的执行非常复杂，涉及许多考虑因素，如：

- 索引和缓存的使用
- 表连接的顺序
- 并发控制
- 事务管理

### SQL语言

在1986年，SQL（结构化查询语言）成为标准。在接下来的40年里，它成为了关系数据库管理系统的主导语言。阅读最新的标准（ANSI SQL 2016）可能会花费很多时间。我如何学习它？

<p>
  <img src="images/how-to-learn-sql.jpg" />
</p>

SQL语言有5个组成部分：

- DDL：数据定义语言，如CREATE, ALTER, DROP
- DQL：数据查询语言，如SELECT
- DML：数据操作语言，如INSERT, UPDATE, DELETE
- DCL：数据控制语言，如GRANT, REVOKE
- TCL：事务控制语言，如COMMIT, ROLLBACK

对于后端工程师来说，你可能需要了解其中的大部分内容。作为数据分析师，你可能需要很好地理解DQL。选择与你最相关的课题。

## 缓存

### 数据无处不在被缓存

这个图表说明了在一个典型架构中我们缓存数据的地方。

<p>
  <img src="images/where do we cache data.jpeg" style="width: 720px" />
</p>

有**多个层级**沿流程。

1. **客户端应用**：HTTP响应可以被浏览器缓存。我们第一次通过HTTP请求数据时，数据会随着HTTP头的过期策略一同返回；再次请求数据时，客户端应用会首先尝试从浏览器缓存中检索数据。
2. **CDN**：CDN缓存静态Web资源。客户端可以从附近的CDN节点获取数据。
3. **负载均衡器**：负载均衡器也可以缓存资源。
4. **消息基础设施**：消息代理首先将消息存储在磁盘上，然后消费者以自己的节奏检索它们。根据保留策略，数据会在Kafka集群中缓存一段时间。
5. **服务**：在服务中有多个缓存层。如果数据未在CPU缓存中，服务将尝试从内存中检索数据。有时服务还有第二级缓存来存储磁盘上的数据。
6. **分布式缓存**：如Redis的分布式缓存将多个服务的键值对存储在内存中。它提供了比数据库更好的读写性能。
7. **全文搜索**：我们有时需要使用全文搜索引擎如Elastic Search进行文档搜索或日志搜索。数据的一份副本也会被索引到搜索引擎中。
8. **数据库**：即使在数据库中，我们也有不同的缓存层：
   - **预写日志(WAL)**：数据首先写入WAL然后构建B树索引
   - **缓冲池**：分配的内存区域用于缓存查询结果
   - **物化视图**：预先计算查询结果并将其存储在数据库表中以提高查询性能
   - **事务日志**：记录所有事务和数据库更新
   - **复制日志**：用于记录数据库集群中的复制状态

### 为什么Redis如此之快？

以下图表展示了Redis快的3个主要原因。

<p>
  <img src="images/why_redis_fast.jpeg" />
</p>

1. **Redis是基于RAM的数据存储**。RAM的访问速度至少比随机磁盘访问快1000倍。
2. **Redis利用了IO多路复用和单线程执行循环来提高执行效率**。
3. **Redis使用了几种高效的底层数据结构**。

问题：另一个流行的内存存储是Memcached。你知道Redis和Memcached的区别吗？

您可能已经注意到这个图表的风格与我之前的None帖子不同。请告诉我您更喜欢哪一个。

### Redis可以怎么用？

<p>
  <img src="images/top-redis-use-cases.jpg" style="width: 520px" />
</p>

Redis不仅仅是缓存。

如图所示，Redis可以用于多种场景。

- **会话**

  我们可以使用Redis在不同的服务之间共享用户会话数据。

- **缓存**

  我们可以使用Redis来缓存对象或页面，特别是热点数据。

- **分布式锁**

  我们可以使用Redis字符串在分布式服务中获取锁。

- **计数器**

  我们可以计数文章的点赞数或阅读次数。

- **限速器**

  我们可以对某些用户IP应用限速器。

- **全局ID生成器**

  我们可以使用Redis的Int类型来生成全局ID。

- **购物车**

  我们可以使用Redis的Hash类型来表示购物车中的键值对。

- **计算用户留存率**

  我们可以使用Bitmap来表示用户每日登录情况并计算用户留存率。

- **消息队列**

  我们可以使用List来实现消息队列。

- **排行榜**

  我们可以使用ZSet来排序文章。

### 顶级缓存策略

设计大型系统通常需要仔细考虑缓存策略。
以下是常用的五种缓存策略。

<p>
  <img src="images/top_caching_strategy.jpeg" style="width: 680px" />
</p>

## 微服务架构

### 典型的微服务架构是什么样的？

<p>
  <img src="images/typical-microservice-arch.jpg" style="width: 520px" />
</p>

下图展示了一个典型的微服务架构。

- **负载均衡器**：这将传入流量分发到多个后端服务。
- **CDN（内容分发网络）**：CDN是一组地理位置分散的服务器，存储静态内容以加快交付速度。客户端首先在CDN中查找内容，然后再访问后端服务。
- **API网关**：处理传入请求并将其路由到相关服务。它与身份提供者和服务发现通信。
- **身份提供者**：处理用户的认证和授权。
- **服务注册与发现**：微服务的注册和发现在此组件中进行，API网关在该组件中查找相关服务进行通信。
- **管理**：此组件负责监控服务。
- **微服务**：微服务按不同领域设计和部署。每个领域有自己的数据库。API网关通过REST API或其他协议与微服务通信，同一领域内的微服务之间使用RPC（远程过程调用）通信。

微服务的优点：

- 可以快速设计、部署和水平扩展。
- 每个领域可以由专职团队独立维护。
- 业务需求可以在每个领域内定制并得到更好的支持。

### 微服务最佳实践

一图胜千言：开发微服务的9个最佳实践。

<p>
  <img src="images/microservice-best-practices.jpeg" />
</p>

在开发微服务时，我们需要遵循以下最佳实践：

1. 为每个微服务使用独立的数据存储
2. 保持代码的成熟度水平相似
3. 每个微服务有独立的构建
4. 给每个微服务分配单一职责
5. 部署到容器中
6. 设计无状态服务
7. 采用领域驱动设计
8. 设计微前端
9. 协调微服务

### 微服务通常使用的技术栈是什么？

下图展示了微服务的技术栈，适用于开发阶段和生产环境。

<p>
  <img src="images/microservice-tech.jpeg" />
</p>

None▶️ **预生产**

- 定义API - 这在前端和后端之间建立了一个契约。我们可以使用Postman或OpenAPI进行此操作。
- 开发 - Node.js或React用于前端开发，Java/Python/Go用于后端开发。我们还需要根据API定义更改API网关的配置。
- 持续集成 - 使用JUnit和Jenkins进行自动化测试。代码被打包成Docker镜像并部署为微服务。

None▶️ **生产环境**

- NGinx是负载均衡器的常见选择。Cloudflare提供CDN（内容分发网络）。
- **API网关** - 我们可以使用Spring Boot作为网关，使用Eureka/Zookeeper进行服务发现。
- 微服务部署在云端。我们可以在AWS、Microsoft Azure或Google GCP之间选择。
- **缓存和全文搜索** - Redis是缓存键值对的常见选择。Elasticsearch用于全文搜索。
- **通信** - 为了让服务之间通信，我们可以使用消息基础设施Kafka或RPC。
- **持久化** - 我们可以使用MySQL或PostgreSQL作为关系数据库，Amazon S3用于对象存储。如果需要，也可以使用Cassandra作为宽列存储。
- **管理与监控** - 为了管理众多微服务，常用的运维工具包括Prometheus、Elastic Stack和Kubernetes。

### 为什么Kafka快？

有许多设计决策促成了Kafka的高性能。在这篇文章中，我们将重点介绍两个。我们认为这两个设计决策对Kafka的性能影响最大。

<p>
  <img src="images/why_is_kafka_fast.jpeg" />
</p>

1. 第一个是Kafka对顺序IO的依赖。
2. 第二个给Kafka性能优势的设计选择是它对效率的关注：零None拷贝原则。

图表说明了数据在生产者和消费者之间的传输方式，以及零None拷贝的含义。

- **步骤1.1 - 1.3：生产者将数据写入磁盘**
- **步骤2：消费者无零None拷贝读取数据**

  2.1 从磁盘加载数据到OS缓存

  2.2 将数据从OS缓存复制到Kafka应用程序

  2.3 Kafka应用程序将数据复制到套接字缓冲区

  2.4 数据从套接字缓冲区复制到网络卡

  2.5 网络卡将数据发送给消费者

- **步骤3：消费者使用零None拷贝读取数据**

  3.1：从磁盘加载数据到OS缓存
  3.2 OS缓存通过sendfile()命令直接将数据复制到网络卡
  3.3 网络卡将数据发送给消费者

零None拷贝是一种快捷方式，节省了应用程序上下文和内核上下文之间的多次数据复制。

## 支付系统

### 如何学习支付系统？

<p>
  <img src="images/learn-payments.jpg" />
</p>

### 为什么信用卡被称为“银行中最赚钱的产品”？VISA/Mastercard是如何赚钱的？

下面的图表显示了信用卡支付流程的经济学。

<p>
  <img src="images/how does visa makes money.jpg" style="width: 640px" />
</p>

1.&nbsp;&nbsp;持卡人向商家支付100美元购买商品。

2.&nbsp;商家通过使用信用卡获得了更高的销售量，并需要向发行银行和卡网络支付费用以提供支付服务。收单银行与商家设定了一个费用，称为“商家折扣费”。

3 - 4. 收单银行保留0.25美元作为收单标记，1.75美元作为交换费支付给发行银行。商家折扣费应覆盖交换费。

  交换费由卡网络设定，因为每个发行银行与每个商家谈判费用效率较低。

5.&nbsp;&nbsp;卡网络与每家银行设定网络评估和费用，每月向卡网络支付其服务费用。例如，VISA对每次刷卡收取0.11%的评估费，加上0.0195美元的使用费。

6.&nbsp;&nbsp;持卡人向发行银行支付其服务费用。

为什么发行银行应该得到补偿？

- 即使持卡人未能向发行银行支付，发行银行也会向商家支付。
- 发行银行在持卡人支付之前就向商家支付。
- 发行银行还有其他运营成本，包括管理客户账户、提供对账单、欺None诈检测、风险管理、清算和结算等。

### 当我们在商店刷信用卡时，VISA是如何工作的？

<p>
  <img src="images/visa_payment.jpeg" />
</p>

VISA、Mastercard和美国运通充当卡网络进行资金清算和结算。卡收单银行和发卡银行可以是——而且通常是——不同的。如果没有中介，银行需要逐一与所有其他银行结算交易，这是相当低效的。

下图展示了VISA在信用卡支付流程中的作用。涉及两个流程。授权流程发生在客户刷卡时。捕获和结算流程发生在商家在当天结束时想要收取款项时。

- 授权流程

步骤0：发卡银行向其客户发行信用卡。

步骤1：持卡人想购买商品并在商店的销售点（POS）终端刷信用卡。

步骤2：POS终端将交易发送给提供POS终端的收单银行。

步骤3和4：收单银行将交易发送给卡网络，也称为卡计划。卡网络将交易发送给发行银行进行批准。

步骤4.1、4.2和4.3：如果交易被批准，发行银行将资金冻结。批准或拒绝信息被发送回给收单方以及POS终端。

- 捕获和结算流程

步骤1和2：商家想要在当天结束时收款，因此他们在POS终端点击“捕获”。交易以批处理的方式发送给收单方。收单方将包含交易的批处理文件发送给卡网络。

步骤3：卡网络对从不同收单方收集的交易进行清算，并将清算文件发送给不同的发行银行。

步骤4：发行银行确认清算文件的正确性，并将资金转移给相关的收单银行。

步骤5：收单银行然后将资金转移给商家的银行。

步骤4：卡网络从不同收单银行清算交易。清算是指相互抵消交易的过程，从而减少总交易数量。

在这个过程中，卡网络承担了与每家银行对话的负担，并因此收取服务费。

### 世界支付系统系列（第一部分）：印度的统一支付接口（UPI）

什么是UPI？UPI是由印度国家支付公司开发的即时实时支付系统。

它目前占印度数字零售交易的60%。

UPI = 支付标记语言 + 支付互操作标准

<p>
  <img src="images/how-does-upi-work.png"  style="width: 600px" />
</p>

## DevOps

### DevOps与SRE与平台工程有什么区别？

DevOps、SRE和平台工程的概念在不同时间由不同的人和组织提出和发展。

<p>
  <img src="images/devops-sre-platform.jpg" />
</p>

DevOps的概念在2009年由Patrick Debois和Andrew Shafer在敏捷大会上提出。他们试图通过促进协作文化和对整个软件开发生命周期的共同责任来弥合软件开发和运维之间的差距。

SRE，或站点可靠性工程，是由Google在2000年代早期开创的，以应对管理大规模、复杂系统的运营挑战。Google开发了SRE实践和工具，如Borg集群管理系统和Monarch监控系统，以提高服务的可靠性和效率。

平台工程是一个较新的概念，在SRE工程的基础上发展而来。平台工程的确切起源不太明确，但通常被理解为是DevOps和SRE实践的扩展，重点在于为产品开发提供支持整个业务视角的综合平台。

值得注意的是，虽然这些概念是在不同时间出现的，但它们都与改善软件开发和运维中的协作、自动化和效率的更广泛趋势有关。

### 什么是k8s（Kubernetes）？

K8s是一个容器编排系统。它用于容器部署和管理。其设计深受Google内部系统Borg的影响。

<p>
  <img src="images/k8s.jpeg" style="width: 680px" />
</p>

一个k8s集群由一组工作机器组成，称为节点，运行容器化应用程序。每个集群至少有一个工作节点。

工作节点（们）托管Pods，Pods是应用程序工作负载的组件。控制平面管理集群中的工作节点和Pods。在生产环境中，控制平面通常跨多台计算机运行，一个集群通常运行多个节点，提供容错和高可用性。

- 控制平面组件

1. **API服务器**

    API服务器与k8s集群中的所有组件对话。所有对Pods的操作都是通过API服务器执行的。

2. **调度器**

    调度器监控Pod工作负载并分配新创建的Pods的负载。

3. **控制器管理器**

    控制器管理器运行控制器，包括节点控制器、作业控制器、端点切片控制器和服务账户控制器。

4. **Etcd**
    
    etcd是一个键值存储，作为Kubernetes的所有集群数据的后端存储。

- 节点

1. **Pods**

    Pod是一组容器，是k8s管理的最小单位。Pods具有应用于Pod内所有容器的单一IP地址。

2. **Kubelet**

    在集群中的每个节点上运行的代理。它确保Pod中的容器正在运行。

3. **Kube Proxy**

    Kube-proxy是运行在每个节点上的网络代理。它负责将进入节点的流量路由到服务。它将工作请求转发到正确的容器。


question = r"""
翻译以下文本,切记保持原本的md格式不变

### Docker vs. Kubernetes. Which one should we use? 

<p>
  <img src="images/docker-vs-k8s.jpg" style="width: 680px" />
</p>



### Docker vs. Kubernetes。我们应该使用哪一个？

<p>
  <img src="images/docker-vs-k8s.jpg" style="width: 680px" />
</p>

什么是Docker？

Docker是一个开源平台，允许你打包、分发并在隔离的容器中运行应用程序。它专注于容器化，提供轻量级的环境，封装应用程序及其依赖项。

什么是Kubernetes？

Kubernetes，通常简称为K8s，是一个开源的容器编排平台。它为自动化部署、扩展和管理跨节点集群的容器化应用程序提供了一个框架。

两者有何不同？

Docker：Docker在单一操作系统主机上操作单个容器级别。

你必须手动管理每个主机，并且为多个相关的容器设置网络、安全策略和存储可能会很复杂。

Kubernetes：Kubernetes在集群级别操作。它管理跨多个主机的多个容器化应用程序，提供自动化任务，如负载平衡、扩展，并确保应用程序的所需状态。

简而言之，Docker专注于容器化和在单个主机上运行容器，而Kubernetes则专门用于管理和在跨主机集群中按比例编排容器。

### Docker是如何工作的？

下图展示了Docker的架构以及我们运行“docker build”、“docker pull”和“docker run”时它的工作原理。

<p>
  <img src="images/docker.jpg" style="width: 680px" />
</p>

Docker架构中有3个组件：

- **Docker客户端**
  
    Docker客户端与Docker守护进程通信。

- **Docker主机**

    Docker守护进程监听Docker API请求并管理Docker对象，如镜像、容器、网络和卷。

- **Docker注册表**

    Docker注册表存储Docker镜像。Docker Hub是一个任何人都可以使用的公共注册表。

以“docker run”命令为例：

  1. Docker从注册表中拉取镜像。
  2. Docker创建一个新的容器。
  3. Docker为容器分配一个读写文件系统。
  4. Docker创建一个网络接口以连接容器到默认网络。
  5. Docker启动容器。

## GIT

### Git命令是如何工作的

首先，我们需要确定代码存储在哪里。通常的假设是只有两个位置 - 一个在远程服务器如Github，另一个在本地机器上。然而，这并不完全准确。Git在我们的机器上维护了三个本地存储位置，这意味着我们的代码可以在四个地方找到：

<p>
  <img src="images/git-commands.png" style="width: 600px" />
</p>

- **工作目录**：我们在这里编辑文件。
- **暂存区**：文件暂时存放的地方，等待下一次提交。
- **本地仓库**：包含已提交的代码。
- **远程仓库**：存储代码的远程服务器。

大多数Git命令主要是在这四个位置之间移动文件。

### Git是如何工作的？

下图展示了Git的工作流程。

<p>
  <img src="images/git-workflow.jpeg" style="width: 520px" />
</p>

Git是一个分布式版本控制系统。

每个开发者都维护主仓库的一个本地副本，并对本地副本进行编辑和提交。

提交速度很快，因为操作不涉及远程仓库。

如果远程仓库崩溃，可以从本地仓库恢复文件。

### Git merge vs. Git rebase

有什么区别？

<p>
  <img src="images/git-merge-git-rebase.jpeg" style="width: 680px" />
</p>

当我们**合并更改**从一个Git分支到另一个时，我们可以使用‘git merge’或‘git rebase’。下图展示了这两个命令的工作方式。

**Git merge**

这会在主分支上创建一个新的提交G'。G'将主分支和功能分支的历史联系起来。

Git merge是**非破坏性的**。既不改变主分支也不改变功能分支。

**Git rebase**

Git rebase将功能分支的历史移动到主分支的头部。它为功能分支中的每个提交创建新的提交E'、F'和G'。

Rebase的优点是它具有线性的**提交历史**。

如果不遵循Git rebase的“黄金法则”，rebase可能是危险的。

**Git Rebase的黄金法则**

永远不要在公共分支上使用它！

## 云服务

### 不同云服务的简洁对比表（2023版）

<p>
  <img src="images/cloud-compare.jpg" />
</p>

### 什么是云原生？

以下是自1980年代以来架构和流程演变的示意图。

<p>
  <img src="images/cloud-native.jpeg" style="width: 640px" />
</p>

组织可以使用云原生技术在公有云、私有云和混合云上构建和运行可扩展的应用程序。

这意味着应用程序被设计为利用云的特性，因此它们对负载具有弹性并且易于扩展。

云原生包括四个方面：

1. **开发过程**

    这个过程已经从None瀑布模型发展到敏捷开发再到DevOps。

2. **应用架构**

    架构已经从单体架构发展到微服务架构。每个服务被设计为小型的，适用于云容器中有限的资源。

3. **部署与打包**

    应用程序过去通常部署在物理服务器上。到了2000年左右，对延迟不敏感的应用程序通常部署在虚拟服务器上。随着云原生应用的出现，它们被打包成Docker镜像并在容器中部署。

4. **应用基础设施**

    应用程序大量部署在云基础设施上，而不是自建服务器上。

## 开发者生产力工具

### 可视化JSON文件

嵌套的JSON文件很难阅读。

**JsonCrack** 可以从JSON文件生成图形图表，使其易于阅读。

此外，生成的图表可以下载为图片。

<p>
  <img src="images/json-cracker.jpeg" />
</p>


### 自动将代码转换为架构图

<p>
  <img src="images/diagrams_as_code.jpeg" style="width: 640px" />
</p>


它能做什么？

- 在Python代码中绘制云系统架构。
- 图表也可以直接在Jupyter Notebooks中渲染。
- 不需要设计工具。
- 支持以下提供商：AWS, Azure, GCP, Kubernetes, 阿里云, Oracle Cloud等。
 
[Github repo](https://github.com/mingrammer/diagrams)

## Linux

### Linux文件系统详解

<p>
  <img src="images/linux-file-systems.jpg" style="width: 680px" />
</p>

Linux文件系统过去像是一个未组织的城镇，人们随意建造房屋。然而，在1994年，引入文件系统层次结构标准（FHS）来规范Linux文件系统的秩序。

通过实施像FHS这样的标准，软件可以确保在各种Linux发行版上保持一致的布局。然而，并非所有Linux发行版都严格遵守这一标准。它们常常加入自己的独特元素或满足特定需求。
要精通这个标准，你可以从探索开始。使用“cd”命令来导航，“ls”命令来列出目录内容。把文件系统想象成一棵树，从根（/）开始。随着时间的推移，你将变得熟练，成为一名熟练的Linux管理员。

### 18个最常用的Linux命令你应该知道

Linux命令是与操作系统交互的指令。它们帮助管理文件、目录、系统进程以及系统的许多其他方面。你需要熟悉这些命令，以便高效而有效地导航和维护基于Linux的系统。

下图展示了常用的Linux命令：

<p>
  <img src="images/18 Most-Used Linux Commands You Should Know-01.jpeg" style="width: 680px" />
</p>


- ls - 列出文件和目录
- cd - 更改当前目录
- mkdir - 创建新目录
- rm - 删除文件或目录
- cp - 复制文件或目录
- mv - 移动或重命名文件或目录
- chmod - 更改文件或目录权限
- grep - 在文件中搜索模式
- find - 搜索文件和目录
- tar - 操作tarball存档文件
- vi - 使用文本编辑器编辑文件
- cat - 显示文件内容
- top - 显示进程和资源使用情况
- ps - 显示进程信息
- kill - 通过发送信号终止进程
- du - 估计文件空间使用
- ifconfig - 配置网络接口  
- ping - 测试主机之间的网络连通性

## 安全性

### HTTPS的工作原理是什么？

超文本传输协议安全（HTTPS）是超文本传输协议（HTTP）的扩展。HTTPS使用传输层安全性（TLS）传输加密数据。如果数据在线被劫持，劫持者只能得到二进制代码。

<p>
  <img src="images/https.jpg" />
</p>


数据是如何加密和解密的？

步骤1 - 客户端（浏览器）和服务器建立TCP连接。

步骤2 - 客户端向服务器发送“客户端问候”。消息中包含一组必要的加密算法（密码套件）和它可以支持的最新TLS版本。服务器以“服务器问候”响应，这样浏览器就知道是否可以支持这些算法和TLS版本。

然后，服务器向客户端发送SSL证书。证书包含公钥、主机名、到期日期等。客户端验证证书。

步骤3 - 验证SSL证书后，客户端生成一个会话密钥并使用公钥加密。服务器接收到加密的会话密钥并使用私钥解密。

步骤4 - 现在，客户端和服务器都持有相同的会话密钥（对称加密），加密数据通过一个安全的双向通道传输。

为什么HTTPS在数据传输期间切换到对称加密？主要有两个原因：

1. **安全性**：非对称加密只支持单向。这意味着如果服务器试图将加密数据发送回客户端，任何人都可以使用公钥解密数据。

2. **服务器资源**：非对称加密增加了相当多的数学负担。它不适合长时间会话的数据传输。

### 用简单词汇解释Oauth 2.0。

OAuth 2.0是一个强大且安全的框架，它允许不同的应用程序代表用户安全地相互交互，而无需共享敏感的凭证。

<p>
  <img src="images/oAuth2.jpg" />
</p>

OAuth涉及的实体包括用户、服务器和身份提供者（IDP）。

**OAuth令牌能做什么？**

当你使用OAuth时，你会得到一个代表你的身份和权限的OAuth令牌。这个令牌可以做几件重要的事情：

- **单点登录（SSO）**：有了OAuth令牌，你可以使用一个登录凭证登录多个服务或应用，使生活更加便捷和安全。
- **跨系统授权**：OAuth令牌允许你在不同系统之间共享你的授权或访问权限，因此你不必在每个地方单独登录。
- **访问用户资料**：拥有OAuth令牌的应用可以访问你允许的用户资料的某些部分，但不会看到全部。

请记住，OAuth 2.0的重点是保护你和你的数据安全，同时在不同应用和服务之间提供无缝且无障碍的在线体验。

### 四种主要的身份验证机制

<p>
  <img src="images/top4-most-used-auth.jpg" />
</p>

1. **SSH密钥**：

    使用加密密钥来安全访问远程系统和服务器

1. **OAuth令牌**：

    提供对第三方应用中的用户数据的有限访问权限的令牌

1. **SSL证书**：

    数字证书确保服务器与客户端之间的安全和加密通信

1. **凭证**：

    用户身份验证信息用于验证和授权访问各种系统和服务

### Session, cookie, JWT, token, SSO和OAuth 2.0 - 它们是什么？

这些术语都与用户身份管理有关。当你登录网站时，你声明了你的身份（识别）。你的身份被验证（认证），然后你被授予必要的权限（授权）。过去提出了许多解决方案，并且列表还在不断增加。

<p>
  <img src="images/session.jpeg" />
</p>

从简单到复杂，这里是我对用户身份管理的理解：

- **WWW-Authenticate** 是最基本的方法。你被浏览器要求输入用户名和密码。由于无法控制登录生命周期，这种方法今天很少使用。

- **会话- cookie** 提供了对登录生命周期的更精细控制。服务器维护会话存储，而浏览器保存会话ID。Cookie通常只适用于浏览器，不适合移动应用。

- 为了解决兼容性问题，可以使用**令牌**。客户端将令牌发送到服务器，服务器验证令牌。其缺点是需要加密和解密令牌，这可能耗时。

- **JWT** 是表示令牌的标准方式。因为它是数字签名的，所以可以验证并信任其中的信息。由于JWT包含签名，服务器端不需要保存会话信息。

- 通过**单点登录（SSO）**，你可以只登录一次并访问多个网站。它使用CAS（中央认证服务）来维护跨站点信息。

- 通过**OAuth 2.0**，你可以授权一个网站访问你在另一个网站上的信息。

### 如何在数据库中安全存储密码以及如何验证密码？

<p>
  <img src="images/salt.jpg" style="width: 720px" />
</p>

**不要做的事情**

- 以明文存储密码是个坏主意，因为任何内部人员都可以看到它们。

- 直接存储密码的哈希值是不够的，因为它容易受到预计算攻击，如彩虹表。

- 为了减轻预计算攻击，我们给密码加盐。

**什么是盐？**

根据OWASP指南，“盐”是添加到每个密码中作为哈希过程一部分的唯一随机生成的字符串。

**如何存储密码和盐？**

1. 哈希结果对每个密码都是唯一的。
1. 密码可以使用以下格式存储在数据库中：`hash(password + salt)`。

**如何验证密码？**

验证密码可以通过以下过程：

1. 客户端输入密码。
1. 系统从数据库中获取对应的盐。
1. 系统将盐附加到密码上并进行哈希。让我们称这个哈希值为H1。
1. 系统比较H1和H2，其中H2是数据库中存储的哈希值。如果它们相同，则密码有效。

### 对10岁孩子解释JSON Web Token（JWT）

<p>
  <img src="images/jwt.jpg" />
</p>

想象你有一个特别的盒子叫做JWT。里面有三部分：一个头部、一个有效载荷和一个签名。

头部就像盒子外面的标签。它告诉我们这是什么类型的盒子，以及它如何被保护。通常它是以JSON格式写的，这是一种用花括号{ }和冒号:来组织信息的方式。

有效载荷就像你想要发送的实际信息或数据。它可以是你的名字、年龄或你想分享的任何其他数据。同样，它也是用JSON格式写的，所以很容易理解和处理。

签名是让JWT安全的部分。它就像一个特殊的封印，只有发送者知道如何创建。签名是使用一个秘密代码（有点像密码）来生成的。这种签名确保了没有人可以在不被发送者知道的情况下None篡改JWT的内容。

当你想要将JWT发送到服务器时，你将头部、有效载荷和签名放入盒子中，然后发送给服务器。服务器可以轻松地读取头部和有效载荷来理解你是谁以及你想做什么。


question = r"""
翻译以下文本,切记保持原本的md格式不变

### How does Google Authenticator (or other types of 2-factor authenticators) work?

Google Authenticator is commonly used for logging into our accounts when 2-factor authentication is enabled. How does it guarantee security?
 
Google Authenticator is a software-based authenticator that implements a two-step verification service. The diagram below provides detail. 

<p>

### Google Authenticator（或其他类型的两因素身份验证器）是如何工作的？

Google Authenticator 通常在启用两因素身份验证时用于登录我们的账户。它是如何保证安全的？

Google Authenticator 是一个基于软件的身份验证器，它实现了两步验证服务。下面的图表提供了详细信息。

<p>
  <img src="images/google_authenticate.jpeg" />
</p>

涉及两个阶段：

- **第一阶段** - 用户启用 Google 两步验证。
- **第二阶段** - 用户使用身份验证器进行登录等操作。

让我们看看这些阶段。

**第一阶段**

步骤 1 和 2：Bob 打开网页以启用两步验证。前端请求一个密钥。身份验证服务为 Bob 生成密钥并将其存储在数据库中。

步骤 3：身份验证服务返回一个 URI 给前端。URI 由密钥发布者、用户名和密钥组成。URI 在网页上以二维码的形式显示。

步骤 4：Bob 然后使用 Google Authenticator 扫描生成的二维码。密钥被存储在身份验证器中。

**第二阶段**
步骤 1 和 2：Bob 想登录一个启用 Google 两步验证的网站。为此，他需要密码。Google Authenticator 每 30 秒使用 TOTP（基于时间的一次性密码）算法生成一个 6 位密码。Bob 使用这个密码进入网站。

步骤 3 和 4：前端将 Bob 输入的密码发送到后端进行身份验证。身份验证服务从数据库中读取密钥，并使用与客户端相同的 TOTP 算法生成一个 6 位密码。

步骤 5：身份验证服务比较客户端和服务器生成的两个密码，并将比较结果返回给前端。只有当两个密码匹配时，Bob 才能继续登录过程。

这种身份验证机制安全吗？

- **其他人能否获取密钥？**

    我们需要确保密钥是通过 HTTPS 传输的。身份验证客户端和数据库存储密钥，我们需要确保这些密钥是加密的。

- **黑客能否猜到 6 位密码？**
    
    不能。密码有 6 位，所以生成的密码有 100 万种可能的组合。加上密码每 30 秒变化一次。如果黑客想在 30 秒内猜出密码，他们需要每秒输入 30,000 种组合。

## 现实世界的案例研究

### Netflix 的技术栈

这篇文章基于许多 Netflix 工程博客和开源项目的研究。如果您发现任何不准确的地方，请随时告知我们。

<p>
  <img src="images/netflix tech stack.png" style="width: 680px" />
</p>

**移动和网页**：Netflix 采用 Swift 和 Kotlin 构建原生移动应用。对于其网络应用程序，它使用 React。

**前端/服务器通信**：Netflix 使用 GraphQL。

**后端服务**：Netflix 依赖 ZUUL、Eureka、Spring Boot 框架等技术。

**数据库**：Netflix 使用 EV 缓存、Cassandra、CockroachDB 等数据库。

**消息/流**：Netflix 采用 Apache Kafka 和 Fink 进行消息和流处理。

**视频存储**：Netflix 使用 S3 和 Open Connect 进行视频存储。

**数据处理**：Netflix 利用 Flink 和 Spark 进行数据处理，然后使用 Tableau 进行可视化。Redshift 用于处理结构化数据仓库信息。

**CI/CD**：Netflix 采用 JIRA、Confluence、PagerDuty、Jenkins、Gradle、Chaos Monkey、Spinnaker、Atlas 等多种工具进行 CI/CD 流程。

### Twitter 架构 2022

是的，这是真实的 Twitter 架构。它由 Elon Musk 发布，我们重新绘制以便于阅读。

<p>
  <img src="images/twitter-arch.jpeg" />
</p>

### Airbnb 微服务架构在过去 15 年的演变

Airbnb 的微服务架构经历了 3 个主要阶段。

<p>
  <img src="images/airbnb_arch.jpeg" />
</p>

**单体架构（2008 - 2017）**

Airbnb 最初是一个简单的房东和客人市场。这是在 Ruby on Rails 应用程序中构建的 - 单体。

挑战是什么？

- 团队所有权混乱 + 无人维护的代码
- 部署缓慢

**微服务（2017 - 2020）**

微服务旨在解决这些挑战。在微服务架构中，关键服务包括：

- 数据获取服务
- 业务逻辑数据服务
- 写入工作流服务
- UI 聚合服务
- 每个服务有一个拥有团队

挑战是什么？

数百个服务和依赖关系对人来说难以管理。

**微 + 宏服务（2020 - 至今）**

这是 Airbnb 当前正在努力的方向。微服务和宏服务混合模型专注于 API 的统一。

### Monorepo 与 Microrepo

哪个最好？为什么不同的公司选择不同的选项？

<p>
  <img src="images/monorepo-microrepo.jpg" />
</p>

Monorepo 并不新鲜；Linux 和 Windows 都是使用 Monorepo 创建的。为了提高可扩展性和构建速度，Google 开发了自己的内部专用工具链来更快地扩展它，并制定了严格的编码质量标准来保持其一致性。

亚马逊和 Netflix 是微服务哲学的主要推广者。这种方法自然将服务代码分成不同的仓库。它扩展得更快，但后来可能会导致治理上的痛点。

在 Monorepo 中，每个服务都是一个文件夹，每个文件夹都有 BUILD 配置和 OWNERS 权限控制。每个服务成员负责自己的文件夹。

另一方面，在 Microrepo 中，每个服务负责自己的仓库，构建配置和权限通常针对整个仓库设置。

在 Monorepo 中，依赖项在整个代码库中共享，无论您的业务如何，所以当有版本升级时，每个代码库都升级它们的版本。

在 Microrepo 中，依赖项在每个仓库内控制。企业根据自己的日程表选择何时升级版本。

Monorepo 有一套标准的检查流程。Google 的代码审查过程以设置高标准而闻名，确保 Monorepo 的质量标准一致，无论业务如何。

Microrepo 可以设置自己的标准或采用共享标准，通过引入最佳实践。它可以为业务更快地扩展，但代码质量可能会有所不同。Google 工程师构建了 Bazel，Meta 构建了 Buck。还有其他开源工具可用，包括 Nx、Lerna 等。

多年来，Microrepo 支持的工具更多，包括 Java 的 Maven 和 Gradle，NodeJS 的 NPM，以及 C/C++ 的 CMake 等。


question = r"""
翻译以下文本,切记保持原本的md格式不变

### How will you design the Stack Overflow website? 

If your answer is on-premise servers and monolith (on the bottom of the following image), you would likely fail the interview, but that's how it is built in reality!

<p>
  <img src="images/stackoverflow.jpg" />
</p>

### 你将如何设计Stack Overflow网站？

如果你回答的是使用本地服务器和单体架构（如图底部所示），你很可能会在面试中失败，但这确实是Stack Overflow的实际架构！

<p>
  <img src="images/stackoverflow.jpg" />
</p>

**人们认为它应该是什么样**

面试官可能会期望看到像图片顶部那样的架构。

- 使用微服务将系统分解为小组件。
- 每个服务都有自己的数据库。重度使用缓存。
- 服务是分片的。
- 服务通过消息队列异步通信。
- 服务采用事件None溯源和CQRS模式实现。
- 展示分布式系统知识，如最终一致性、CAP定理等。

**实际情况**

Stack Overflow仅使用9台本地服务器就处理了所有流量，而且它是单体架构！它有自己的服务器，并不运行在云端。

这与我们今天的流行观点相None悖。

### 为什么亚马逊Prime Video的监控系统从无服务器架构转向单体架构？如何节省90%的成本？

下图展示了迁移前后的架构对比。

<p>
  <img src="images/serverless-to-monolithic.jpeg" />
</p>

什么是亚马逊Prime Video监控服务？

Prime Video服务需要监控数千个直播流的质量。监控工具实时自动分析流并识别质量问题，如块损坏、视频冻结、同步问题等。这对客户满意度至关重要。

有三个步骤：媒体转换器、缺陷检测器和实时通知。

- 旧架构的问题是什么？

  旧架构基于Amazon Lambda，适合快速构建服务。但在大规模运行时并不划算。两个最昂贵的操作是：

1. 编排工作流 - AWS Step Functions按状态转换收费，每秒执行多次状态转换。

2. 分布式组件之间的数据传输 - 中间数据存储在Amazon S3，以便下一阶段下载。当数据量很大时，下载成本很高。

- 单体架构节省90%的成本

  单体架构旨在解决成本问题。仍然有三个组件，但媒体转换器和缺陷检测器部署在同一个进程中，节省了网络传输数据的成本。令人惊讶的是，这种部署架构的改变导致了90%的成本节省！

这是一个有趣且独特的案例研究，因为微服务在科技行业已成为一种时尚的选择。看到我们正在进行更多关于架构演进的讨论，并更诚实地讨论其优缺点是非常好的。将组件分解成分布式微服务是有成本的。

- 亚马逊领导层对此说了什么？

  亚马逊CTO Werner Vogels：“构建**可演进的软件系统**是一种策略，不是宗教。重新审视你的架构，保持开放的心态是必须的。”

  前亚马逊可持续发展副总裁Adrian Cockcroft：“Prime Video团队遵循了我称为**无服务器优先**的路径……我不提None倡**仅无服务器**。”

### Disney Hotstar如何在比赛期间捕获50亿个表情符号？

<p>
  <img src="images/hotstar_emojis.jpeg" style="width: 720px" />
</p>

1. 客户端通过标准HTTP请求发送表情符号。你可以把Golang服务看作一个典型的Web服务器。选择Golang是因为它支持并发性好，Golang的线程很轻量。

2. 由于写入量非常高，Kafka（消息队列）用作缓冲。

3. 表情符号数据由一个名为Spark的流处理服务聚合。每2秒聚合一次数据，这是可配置的。时间间隔的选择涉及到权衡。更短的时间间隔意味着表情符号更快地传递给其他客户端，但也意味着需要更多的计算资源。

4. 聚合数据写入另一个Kafka。

5. PubSub消费者从Kafka中拉取聚合的表情符号数据。

6. 表情符号通过PubSub基础设施实时传递给其他客户端。Hotstar考虑了以下协议：Socketio、NATS、MQTT和gRPC，最终选择了MQTT。

LinkedIn采用了类似的设计来流式传输每秒百万个点赞。

### Discord如何存储万亿条消息

下图展示了Discord消息存储的演变：

<p>
  <img src="images/discord-store-messages.jpg" />
</p>

MongoDB ➡️ Cassandra ➡️ ScyllaDB 

在2015年，Discord的第一版构建在单个MongoDB副本之上。到了2015年11月，MongoDB存储了1亿条消息，RAM无法再容纳数据和索引，延迟变得不可预测。消息存储需要转移到另一个数据库，选择了Cassandra。

在2017年，Discord拥有12个Cassandra节点，存储了数十亿条消息。

到了2022年初，它拥有177个节点，存储了万亿条消息。此时，延迟不可预测，维护操作变得非常昂贵。

问题有几个：

- Cassandra使用LSM树作为内部数据结构。读取比写入更昂贵。服务器上可能有数百个用户同时读取，导致热点。
- 维护集群，如压缩SSTables，会影响性能。
- None垃None圾回收暂停会导致显著的延迟峰值。

ScyllaDB是一个与Cassandra兼容的数据库，由C++编写。Discord重新设计了其架构，采用了单体API、用Rust编写的服务，以及基于ScyllaDB的存储。

在ScyllaDB中，p99读延迟为15ms，而在Cassandra中为40-125ms。p99写延迟为5ms，而在Cassandra中为5-70ms。

### 视频直播在YouTube、TikTok直播或Twitch上是如何工作的？

直播与常规流媒体不同，因为视频内容通过互联网实时传输，通常延迟只有几秒。

下图解释了这一切是如何实现的。

<p>
  <img src="images/live_streaming_updated.jpg" style="width: 640px" />
</p>

步骤1：原始视频数据由麦克风和摄像头捕获。数据发送到服务器端。

步骤2：视频数据被压缩和编码。例如，压缩算法将背景和其他视频元素分开。压缩后，视频被编码成如H.264这样的标准。经过这一步，视频数据的大小大大减小。

步骤3：编码后的数据被分割成较小的段，通常是几秒长，这样下载或流媒体所需的时间就大大减少了。

步骤4：分割的数据发送到流媒体服务器。流媒体服务器需要支持不同的设备和网络条件。这称为‘自适应比特率流媒体’。这意味着在步骤2和3中需要生成不同比特率的多个文件。

步骤5：直播数据被推送到由CDN（内容分发网络）支持的边缘服务器。数百万观众可以从附近的边缘服务器观看视频。CDN显著降低了数据传输延迟。

步骤6：观众的设备解码和解压视频数据，并在视频播放器中播放。

步骤7和8：如果视频需要存储以供重播，编码数据将发送到存储服务器，观众可以稍后请求重播。

直播的标准协议包括：

- RTMP（实时消息协议）：最初由Macromedia开发，用于在Flash播放器和服务器之间传输数据。现在用于通过互联网流媒体视频数据。注意，像Skype这样的视频会议应用程序使用RTC（实时通信）协议以获得更低的延迟。
- HLS（HTTP直播流）：需要H.264或H.265编码。Apple设备只接受HLS格式。
- DASH（动态自适应流媒体）：不支持Apple设备。
- HLS和DASH都支持自适应比特率流媒体。

## 许可证

<p xmlns:cc="http://creativecommons.org/ns#">本作品根据<a href="http://creativecommons.org/licenses/by-nc-nd/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY-NC-ND 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/nd.svg?ref=chooser-v1"></a>进行许可。</p>None
